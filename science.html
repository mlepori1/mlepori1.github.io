<meta name="viewport" content="width=device-width, initial-scale=1.0">

<head>
    <!-- This will show up on the tab in your browser -->
    <title>Michael Lepori</title>

    <!-- This links your css file to the html -->
    <link rel="stylesheet" type="text/css" href="index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>



<!-- Header Menu of the Page -->
<header>
         
    <!-- Top header menu containing
         logo and Navigation bar -->
    <div id="top-header"> 
                 
        <!-- Navigation Menu -->
        <nav>
            <div class="menu" id="menu">
              <a href="index.html">Home</a></li>
              <a href="science.html">Science</a></li>
              <a href="misc.html">Misc.</a></li>
              <a href="https://drive.google.com/file/d/1cMbbUgXVoc981DpVBFS6Yr4egvPipL5e/view?usp=sharing">CV</a></li>
              <h2>Michael Lepori</h2>
              <button type="button" onclick="window.location.href='https://scholar.google.com/citations?user=G1fepc8AAAAJ&hl=en&oi=ao'";>Google Scholar</button>
              <a href="javascript:void(0);" class="icon" onclick="responsiveMenu()">
                  <i class="fa fa-bars"></i>
              </a>
          </div>
          </nav>
    </div>   
 
</header>

<body>
    <div class="brain_banner"></div>

    <!-- This is the start of the "Science" section -->
    
    <div id="science-header">
        <h1>Research Directions</h1>
        <div class="research-directions">
           <div class="proj-left-text">
                <p>My work focuses on understanding the representations and algorithms underlying human and machine cognition. For the first time, we have access to
                    models that can flexibly accomplish complex cognitive tasks across a wide range of domains. My research uses insights from cognitive science in order
                    to uncover the mechanisms supporting this seemingly-intelligent behavior, and, reciprocally, uses techniques from mechanistic interpretability to better characterize 
                    the similarities and differences between minds and machines. Ultimately, this research program aims to transform black-box neural networks into explicit and useful cognitive
                    models of linguistic and visual processing, while also driving the development of more human-like artificial intelligence systems. 
                </p>

                <p>Here are some specific questions that I like to think about:</p>
                <ul class="spaced-list">
                <li>How do modern neural networks seem to produce compositional/symbolic behavior? </li>
                <li>To what extent to language models learn to represent a coherent model of the world? </li>
                <li>How can we best employ pretrained models as (components of) cognitive models? </li>
                <li>How much of human cognition is truly symbolic, and how much is statistical? </li>
                <li>What is the role of inductive biases in modern AI? Is scale all you need? </li> 
                </ul>
            </div>

        </div>

    </div>

    <div id="projects-header">
        <h1>Selected Publications</h1>
    </div>

    <div class="projects">

        <div class="project">
            <img src="assets/just_fantasy.png" alt="Just Fantasy Diagram", id="right-im-container">
            <div class="proj-left-text">
                <h2>Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility</h2>
                <p>Can language models distinguish the possible from the impossible?</p>
            </div>
            <button class="left-button" type="button" onclick="window.location.href='https://arxiv.org/abs/2507.12553'">Read</button>
        </div>

        <div class="project">
            <img src="assets/racing_thoughts.png" alt="Racing Thoughts Diagram", id="left-im-container-wide">
            <div class="proj-right-text">
                <h2>Racing Thoughts: Explaining Contextualization Errors in Large Language Models</h2>
                <p>Language models are usually great at incorporating context &mdash; but not always. What causes contextualization errors?</p>
            </div>
            <button class="right-button" type="button" onclick="window.location.href='https://aclanthology.org/2025.naacl-long.155/'">Read</button>
        </div>


        <div class="project">
            <img src="assets/beyond_the_doors.png" alt="Beyond the Doors Diagram", id="right-im-container-wide">
            <div class="proj-left-text">
                <h2>Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects</h2>
                <p>How do vision transformers solve a simple symbolic visual reasoning task?</p>
            </div>
            <button class="left-button" type="button" onclick="window.location.href='https://proceedings.neurips.cc/paper_files/paper/2024/hash/ed99503856b2ba85092e5413add65d86-Abstract-Conference.html'">Read</button>
        </div>


        <div class="project">
            <img src="assets/break_it_down_img.png" alt="Break It Down Diagram", id="left-im-container">
            <div class="proj-right-text">
                <h2>Break It Down: Evidence for Structural Compositionality in Neural Networks</h2>
                <p>Do neural networks self-organize into modular components when solving compositional tasks?</p>
            </div>
            <button class="right-button" type="button" onclick="window.location.href='https://arxiv.org/abs/2301.10884'">Read</button>
        </div>

    <div class="footer">
        <p>michael_lepori@brown.edu</p>
    </div>
</body>


<!--Add extremely simple JS function to make menu responsive-->
<script>
    function responsiveMenu() {
      var x = document.getElementById("menu");
      if (x.className === "menu") {
        x.className += " responsive";
      } else {
        x.className = "menu";
      }
    }
</script>
